---
title: "session 3 notes"
author: "Tim Riffe"
date: "2025-07-09"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# usage of new lifetable function, `lt_full()`

To load, you can source straight from github like so:
```{r, message = FALSE}
library(tidyverse)
library(janitor)
source("https://raw.githubusercontent.com/timriffe/BSSD2025Module2/refs/heads/master/02_lifetables.R")
```

To use, you need to group your data
```{r}
D <- read_csv("https://github.com/timriffe/BSSD2025Module2/raw/refs/heads/master/data/ES_mort.csv.gz",show_col_types = FALSE) |> 
  clean_names()

D |> 
  mutate(mx = if_else(is.na(mx) | mx == 0, .5, mx)) |> 
  filter(sex != "total") |> 
  group_by(year, sex) |> 
  group_modify(~lt_full(data= .x, groups = .y))
```


# calculate all WPP lifetables:

load it:
```{r}
wpp <- 
  read_csv("https://github.com/timriffe/BSSD2025Module2/raw/refs/heads/master/data/mxwpp.csv.gz", show_col_types = FALSE)
```



# add iso3 codes and filter down to countries only
```{r, warning = FALSE}
#install.packages("countrycode")
library(countrycode)
wpp <-
  wpp |> 
  mutate(iso = countrycode(sourcevar = un_code, 
            origin = "un", 
            destination = "iso3c")) |> 
  filter(!is.na(iso)) 
```

# 
Now calculate lifetable for each subset (year, sex, location); notice eval = FALSE, because I'm not patient.

```{r, eval = FALSE}
wpp_lt <-
  wpp |> 
  mutate(sex = if_else(sex == "m","male","female")) |> 
  group_by(iso, year, sex) |> 
  reframe(lt_full2(age = age, 
                   mx = mx, 
                   sex = sex,
                   radix = 1e5))
```

Now I've taken the time to refactor this code to run in parallel. This will adapt to your machine somewhat. I have 8 cores, so it will use 7 of them
```{r}
library(purrr)
library(furrr)
# set up the workers
plan(multisession, workers = parallel::detectCores() - 1)

# First, cut down data,
wpp <- wpp |>
  mutate(sex = if_else(sex == "m", "male", "female")) |>
  select(iso, year, sex, age, mx) |>
  filter(year < 2022) |> 
  # now apply groups and actually split the data
  group_by(iso, year, sex) |>
  group_split() |>
  future_map(\(df) {
    lt_full2(
      age = df$age,
      mx = df$mx,
      sex = df$sex[1],
      radix = 1e5
    ) |>
      # keep grouping info... easy to forget this
      mutate(
        iso = df$iso[1],
        year = df$year[1],
        sex = df$sex[1]
      )
  }) |>
  bind_rows()

#Manually shut down parallel workers when done
plan(sequential)
gc()
```


```{r}
wpp |> 
  filter(year %% 10 == 0) |> 
  ggplot(aes(x = age, y = mx, group = interaction(year,iso))) +
  geom_line(alpha = .05) +
  scale_y_log10() +
  facet_wrap(~sex)
```

# 

1. use `countrycode` package to add a column for `continent`
2. create a column called `decade`.
```{r}
year <- 1950:2020
decade <- year - year %% 10
```
3. use this helper function to estimate a slope of increase in life expectancy at birth, for each decade and continent. Tip: use `summarize()`
```{r}
slope_helper <- function(year, e0){
  coefs <- lm(e0~year) |> coef()
  coefs["year"]
}
```
4. display result as a table with decades in columns and continents in rows

```{r}
wpp |> 
  mutate(continent = countrycode(iso, 
                                 origin = "iso3c", 
                                 destination = "continent"),
         decade = year - year %% 10) |> 
  filter(age == 0, year < 2020) |> 
  group_by(decade, continent) |> 
  summarize(pace = slope_helper(year = year, e0 = ex),
            .groups = "drop") |> 
  mutate(pace = round(pace,2)) |> 
  pivot_wider(names_from = decade, values_from = pace)
```

```{r}
wpp |> 
  filter(age == 0,
         year < 2020,
         sex == "female") |> 
  mutate(continent = countrycode(iso, 
                                 origin = "iso3c", 
                                 destination = "continent")) |> 
  ggplot(aes(x = year, y = ex, group = iso, color= continent)) +
  geom_line(alpha = .3)
```

# let's standardize

Recall the formula for a weighted mean:

$$ \bar{x} = \frac{\sum x_i \cdot w_i}{\sum w_i} $$

```{r}
standards <- read_csv("https://raw.githubusercontent.com/timriffe/BSSD2025Module2/refs/heads/master/data/standards_abridged.csv", show_col_types = FALSE)

standards |> 
  group_by(standard) |> 
  mutate(n = c(diff(age),1)) |> 
  ungroup() |> 
  filter(grepl(standard, pattern = "World") | grepl(standard, pattern = "European")) |> 
  ggplot(aes(x = age, y = pop / n, color = standard)) +
  geom_step()
```

$$ \bar{x} = \frac{\sum x_i \cdot w_i}{\sum w_i} $$

First, pick out a standard, then discount the values from abridged ages to what they would be for single ages. Easiest to just assume a constant weight in each age group. It's OK since it's just used for weighting. In our case, just take care that the open age group extends as far as needed in the wpp data (up to 100+ rather than 90+)
```{r}
world_standard <-
  standards |> 
  filter(grepl(standard, pattern = "World")) |> 
  mutate(n = c(diff(age),11),
         w = pop / n) |> 
  rename(age_abr = age) |> 
  select(age_abr, w)
```

Now we need to figure out which abridged age each single age falls within. This three-step processing (`if_else()`) could be reframed as a `case_when()` call, but my mind isn't there right now, sry. Then we're ready to merge the standard to the wpp lifetables using the new `age_abr` column. The age-standardized death rates are then the weighted mean of age-specific death weights using the standard as the weights (`w`).
```{r}
wpp |> 
  mutate(age_abr = age - age %% 5,
         age_abr = if_else(between(age,1,4),1,age_abr),
         age_abr = if_else(age >= 90, 90, age_abr)) |> 
  left_join(world_standard, by = join_by(age_abr)) |> 
  group_by(iso, sex, year) |> 
  summarize(sdr  = 1000 * sum(mx * w))
```

In practice age-standardization is most common in the literature in spatial epidemiology, where the values usually end up on choropleth maps (color maps). Although this does a good job of picking out high vs low, using the rate scale as the unit of reporting is still IMO coming too short vis what could be done.

# Decomposition

```{r}
# library(pak)
# pak("timriffe/DemoTools")
```


Let's read in some new data :-)
```{r}
library(tidyverse)
library(readxl)
source("https://raw.githubusercontent.com/timriffe/BSSD2025Module2/refs/heads/master/02_lifetables.R")
ghana <- read_excel("data/Ghana sampleData.xlsx")
ghalt <-
  ghana |> 
  clean_names() |> 
  select(age_group, male_pop, female_pop, 
         male_deaths, female_deaths) |> 
  mutate(male = male_deaths / male_pop,
         female = female_deaths / female_pop) |> 
  select(age_group, male, female) |> 
  pivot_longer(c(male, female), names_to = "sex", values_to = "mx") |> 
  mutate(age = if_else(age_group == "<1",0, parse_number(age_group))) |> 
  arrange(sex, age) |> 
  group_by(sex) |> 
  group_modify(~lt_full(data = .x, groups = .y)) 

# wpp_iso |> 
#   filter(year == 2021, iso == "GHA", age == 0)
```

Life expectancy differences MUST be due to differences in age-specific rates

```{r}
ghalt |> 
  select(age, sex, mx) |> 
  pivot_wider(names_from = sex, values_from = mx) |> 
  mutate(ratio = male / female) |> 
  ggplot(aes(x = age, y = ratio)) +
  geom_line() +
  scale_y_log10()
```

The difference in life expectancy at birth, $\Delta$
$$ \Delta = e_0^f - e_0^m  $$

$$ e_0 = f(m_x) $$

Additivity of age-specific contributions
$$ \Delta = \sum \delta_x$$

$$ \mathbf{\delta}  = \mathcal{D}(f(),m_x^f, m_x^m)$$

The fancy D can be any kind of decomposition approach. For the case of life expectancy there are some that are based on tranformations of lifetable columns. For example, Arriaga or Chandrasekaran. Or you could take a totally different approach.

$$ e_0 = f(m_x) $$

Imagine a sensitivity function for your index of interest. This tells you how much the index changes per unit of perturbation in the input parameters. This might have an analytic expression (it does for lifetables), or you might get it from a numerical gradient function. This function goes by different names in different disciplines: sensitivity function; gradient function; partial derivative, and surely others.
$$ s(f(), m_x) $$
in our case $$\frac{\partial e_0}{\partial m_x}$$

$$ \delta = s(f(), \bar{m_x}) \cdot (m_x^m - m_x^f)$$
$$ \frac{\partial e_0}{\partial m_x} = -\ell(x)e(x)$$
This is all for the sake of generality

Let's use a pacakge

```{r}
# remotes::install_github("timriffe/LEdecomp")
library(LEdecomp)
library(DemoTools)
fem <- ghalt |> filter(sex == "female")
male <- ghalt |> filter(sex == "male")
flt <- lt_abridged2single(nMx = fem$mx,
                   Age = fem$age,
                   OAnew = 100,
                   Sex = "f") |> 
  mutate(sex = "female")
mlt <- lt_abridged2single(nMx = male$mx,
                   Age = male$age,
                   OAnew = 100,
                   Sex = "m")|> 
  mutate(sex = "male")
gha1 <- bind_rows(flt, mlt)
gha1 |> 
  filter(between(Age, 85,95))

  gha1 |> 
  select(age = Age,sex,mx = nMx) |> 
  pivot_wider(names_from = sex, values_from = mx) |> 
  mutate(mx_avg = (male + female) / 2,
         sen = sen_e0_mx_lt(mx = mx_avg, 
                            age = age, 
                            sex = "t", 
                            closeout = TRUE),
         mx_diff = female - male,
         delta = sen * mx_diff) |> 
    summarize(Delta = sum(delta))
```

# let's take a look at generalized decomposition

```{r}
library(DemoDecomp)
```

LTRE Lifetable Response Experiment

```{r}
# ltre()
```

Stepwise replacement
```{r}
# stepwise_replacement()
```

Horiuchi - pseudocontinuous decomposition, or the linear integral decomposition method.

```{r}
# horiuchi()
```

What you need to do to use any of these functions is write your function so that it can calculate your output using a single vector of parameters.

```{r}
mx_to_e0 <- function(mx, age, sex = "female"){
  lt <- lt_full2(mx = mx, age = age, sex = sex)
  lt$ex[1]
}
```

Usage:
```{r}
gha_dec <-
  ghalt |> 
  select(sex,age,mx) |> 
  pivot_wider(names_from = sex, values_from = mx) |> 
  mutate(deltaf = horiuchi(mx_to_e0, male, female, sex = "female",age = age, N = 20),
         deltam = horiuchi(mx_to_e0, male, female, sex = "male",age = age, N = 20),
         delta = (deltaf + deltam) / 2)

gha_dec |> 
  mutate(nx = c(diff(age),1)) |> 
  ggplot(aes(x =age, y = delta / nx)) +
  geom_line()
```


# Excercise 
1. load (recreate) the Spanish rates we used on Tuesday.
2. pick out males or females in 1960,1980,2000,2019
3. decompose the change in life expectancy from 1960-1980, 1980-2000, 2000-2019
4. plot the age patterns of the contributions of mortality in each age for the three periods,
this can be 3 lines on one plot.

I will give a separate script to solve this tomorrow, but have at it

```{r}
D <- read_csv("https://github.com/timriffe/BSSD2025Module2/raw/refs/heads/master/data/ES_mort.csv.gz",show_col_types = FALSE) |> 
  clean_names()
```

1.  filter
```{r}
D <-
  D |> 
  filter(sex == "female",
         year %in% c(1960,1980,2000,2019))|> 
  mutate(mx = if_else(is.na(mx), .5, mx),
         mx = if_else(mx == 0, .5, mx))
```

2. I will use two different approaches:
(1) a symmetrical variant of Arriaga decomposition,
(2) horiuchi decomposition.

These are the values whose changes we want to decompose:
```{r}
e0 <-
  D |> 
  select(-exposure) |> 
  arrange(age,year) |> 
  group_by(year) |> 
  summarize(e0 = mx_to_e0(mx,age,sex="female"))
e0$e0 |> diff()
```
Due to differences in these rates:
```{r}
D |>
  ggplot(aes(x = age,y = mx, color = year, group = year)) +
  geom_line() +
  scale_y_log10() +
  theme_minimal()
```

Do the decomposition
```{r}
library(DemoDecomp)
dec <-
  D |> 
  select(-exposure) |> 
  arrange(age,year) |> 
  group_by(age) |> 
  mutate(mx2 = lead(mx)) |> 
  ungroup()  |> 
  filter(!is.na(mx2)) |> 
  arrange(year,age) |> 
  group_by(year) |> 
  mutate(delta_x = arriaga_sym(mx1 = mx,mx2 = mx2,age=age,sex1="f",closeout = TRUE),
         delta_x_horiuchi = horiuchi(mx_to_e0,mx,mx2,N=20,age=age,sex="female"))
```

check sums:
```{r}
dec |> 
  group_by(year) |> 
  summarize(Delta_arr = sum(delta_x),
            Delta_hor = sum(delta_x_horiuchi)) |> 
  mutate(Delta_check = e0 |> pull(e0) |> diff())
```

Visualize age patterns: which ages drive progress?

```{r}
dec |> 
  ggplot(aes(x=age, y = delta_x, color = as.factor(year))) +
  geom_line() +
  theme_minimal()
```

Pretty impressive m0 power early on. All in one age. Whereas older-age contributions are spread out. Let's group by 10-year age groups (using modulo)

```{r}
dec |> 
  ungroup() |> 
  mutate(age = age - age %% 10) |> 
  group_by(year,age) |> 
  summarize(delta_x = sum(delta_x)) |> 
  ungroup() |> 
  ggplot(aes(x =age, y = delta_x, fill = as.factor(year))) +
  geom_col(position = "dodge2") +
  theme_minimal()
```











